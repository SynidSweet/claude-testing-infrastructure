name: Core Infrastructure Tests

on:
  push:
    branches: [ main, develop, feature/*, fix/* ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'

jobs:
  test:
    name: Test Suite
    runs-on: ${{ matrix.os }}
    timeout-minutes: 15
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        node-version: [18, 20]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build infrastructure
        run: npm run build

      - name: Verify CLI availability
        run: |
          echo "Testing CLI availability..."
          CLI_OUTPUT=$(node dist/cli/index.js --version)
          echo "CLI output: $CLI_OUTPUT"
          
          # Extract version number
          CLI_VERSION=$(echo "$CLI_OUTPUT" | tail -n 1)
          echo "✅ CLI version: $CLI_VERSION"

      - name: Run lint checks
        run: npm run lint
        continue-on-error: true

      - name: Run format checks
        run: npm run format:check
        continue-on-error: true

      - name: Run core tests
        run: npm test
        env:
          CI: true  # This ensures AI tests are automatically skipped via Jest config

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: test-results-${{ matrix.os }}-node${{ matrix.node-version }}
          path: |
            coverage/
            test-results/
            *.log

  coverage:
    name: Coverage Report
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build infrastructure
        run: npm run build

      - name: Generate coverage report
        run: npm run test:coverage
        env:
          CI: true

      - name: Upload coverage to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage/

      - name: Comment coverage on PR
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            if (fs.existsSync('coverage/lcov-report/index.html')) {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `## 📊 Test Coverage Report\n\nCore infrastructure test coverage report has been generated. Check the workflow artifacts for detailed coverage information.\n\n> **Note**: AI validation tests are excluded from CI runs to maintain fast feedback loops. Run tests locally for comprehensive validation.`
              });
            }

  quality-checks:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: test
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build infrastructure
        run: npm run build

      - name: Run comprehensive quality checks
        run: |
          echo "🔍 Running quality checks..."
          
          # Check for TypeScript compilation errors
          npx tsc --noEmit
          
          # Verify all core modules can be imported
          node -e "
            const analyzer = require('./dist/analyzers/ProjectAnalyzer');
            const generator = require('./dist/generators/TestGenerator');
            const runner = require('./dist/runners/TestRunnerFactory');
            console.log('✅ All core modules imported successfully');
          "
          
          # Test CLI functionality
          echo "Testing CLI commands..."
          node dist/cli/index.js --help > /dev/null
          node dist/cli/index.js --version > /dev/null
          echo "✅ CLI commands functional"

      - name: Validate configuration
        run: |
          echo "🔧 Validating configuration system..."
          node -e "
            const config = require('./dist/config/ConfigurationService');
            console.log('✅ Configuration system validated');
          "

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security audit
        run: npm audit --audit-level moderate

      - name: Check for vulnerable dependencies
        run: |
          echo "🔒 Checking for security vulnerabilities..."
          npm audit --audit-level high --dry-run || echo "⚠️ High-severity vulnerabilities found"

  production-validation:
    name: Production Validation
    runs-on: ubuntu-latest
    needs: [test, quality-checks]
    if: github.ref == 'refs/heads/main' || github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build infrastructure
        run: npm run build

      - name: Run production readiness check
        run: |
          echo "🔍 Running production readiness validation..."
          npm run validation:production
        env:
          SKIP_AI_TESTS: 1  # Skip AI tests for faster CI execution

      - name: Generate validation report
        run: |
          echo "📊 Generating comprehensive validation report..."
          npm run validation:report -- --skip-ai-tests --output validation-report.md
        
      - name: Upload validation report
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: validation-report.md

      - name: Run deployment checklist (dry run)
        if: github.ref == 'refs/heads/main'
        run: |
          echo "🚀 Running deployment readiness checklist..."
          npm run validation:deployment -- --skip-ai-tests --output deployment-checklist.json
          
      - name: Upload deployment checklist
        if: github.ref == 'refs/heads/main'
        uses: actions/upload-artifact@v4
        with:
          name: deployment-checklist
          path: deployment-checklist.json

      - name: Comment validation summary on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            let comment = "## 🏗️ Production Validation Results\n\n";
            
            try {
              if (fs.existsSync('validation-report.md')) {
                const report = fs.readFileSync('validation-report.md', 'utf8');
                const scoreMatch = report.match(/Overall Quality Score.*?(\d+\.?\d*)%/);
                const readyMatch = report.match(/Production Ready.*?(✅ YES|❌ NO)/);
                
                if (scoreMatch && readyMatch) {
                  comment += `**Quality Score**: ${scoreMatch[1]}%\n`;
                  comment += `**Production Ready**: ${readyMatch[1]}\n\n`;
                }
                
                comment += "📊 Full validation report available in workflow artifacts.\n\n";
              }
              
              comment += "> **Note**: This validation runs with AI tests skipped for CI performance. ";
              comment += "Run full validation locally with all AI tests for comprehensive analysis.";
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.log('Could not post validation comment:', error.message);
            }

  summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [test, coverage, quality-checks, security, production-validation]
    if: always()
    
    steps:
      - name: Generate CI summary
        run: |
          echo "# 🚀 CI Pipeline Summary" > ci-summary.md
          echo "**Workflow**: ${{ github.workflow }}" >> ci-summary.md
          echo "**Run ID**: ${{ github.run_id }}" >> ci-summary.md
          echo "**Trigger**: ${{ github.event_name }}" >> ci-summary.md
          echo "**Branch**: ${{ github.ref_name }}" >> ci-summary.md
          echo "" >> ci-summary.md
          
          echo "## Job Results" >> ci-summary.md
          echo "- **Core Tests**: ${{ needs.test.result == 'success' && '✅ Passed' || '❌ Failed' }}" >> ci-summary.md
          echo "- **Coverage**: ${{ needs.coverage.result == 'success' && '✅ Generated' || needs.coverage.result == 'skipped' && '⏭️ Skipped' || '❌ Failed' }}" >> ci-summary.md
          echo "- **Quality Checks**: ${{ needs.quality-checks.result == 'success' && '✅ Passed' || '❌ Failed' }}" >> ci-summary.md
          echo "- **Security Scan**: ${{ needs.security.result == 'success' && '✅ Passed' || '❌ Failed' }}" >> ci-summary.md
          echo "- **Production Validation**: ${{ needs.production-validation.result == 'success' && '✅ Passed' || needs.production-validation.result == 'skipped' && '⏭️ Skipped' || '❌ Failed' }}" >> ci-summary.md
          echo "" >> ci-summary.md
          
          echo "## Test Configuration" >> ci-summary.md
          echo "- **AI Tests**: Automatically skipped in CI (run locally for full validation)" >> ci-summary.md
          echo "- **Platforms**: Ubuntu, macOS" >> ci-summary.md
          echo "- **Node Versions**: 18, 20" >> ci-summary.md
          echo "" >> ci-summary.md
          
          # Determine overall status
          OVERALL_STATUS="✅ ALL CHECKS PASSED"
          if [[ "${{ needs.test.result }}" != "success" ]]; then
            OVERALL_STATUS="❌ FAILED - Core tests failed"
          elif [[ "${{ needs.quality-checks.result }}" != "success" ]]; then
            OVERALL_STATUS="❌ FAILED - Quality checks failed"
          elif [[ "${{ needs.security.result }}" != "success" ]]; then
            OVERALL_STATUS="⚠️ WARNING - Security issues detected"
          fi
          
          echo "## Overall Status: $OVERALL_STATUS" >> ci-summary.md
          
          cat ci-summary.md

      - name: Upload CI summary
        uses: actions/upload-artifact@v4
        with:
          name: ci-summary
          path: ci-summary.md

      - name: Set final status
        run: |
          if [[ "${{ needs.test.result }}" != "success" ]]; then
            echo "❌ Core tests failed - failing CI"
            exit 1
          elif [[ "${{ needs.quality-checks.result }}" != "success" ]]; then
            echo "❌ Quality checks failed - failing CI"
            exit 1
          fi
          
          echo "✅ CI pipeline completed successfully"